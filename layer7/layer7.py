# -*- coding: utf-8 -*-
"""layer7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wl95N20ktf8bLNWwRTf-HHkcHDHwZKLM
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, f_classif, chi2
from sklearn.model_selection import RandomizedSearchCV

#functions to predict and check accuray
def AccuracyScore(model, x_valid, y_valid):
    y_pred = model.predict(x_valid)
    accuracy = accuracy_score(y_valid, y_pred)
    print("Accuracy: %.2f%%" % (accuracy * 100.0))
    return accuracy

def correlation(dataset, threshold):
    col_corr = set()  # Set of all the names of correlated columns
    corr_matrix = dataset.corr()
    for i in range(len(corr_matrix.columns)):
        for j in range(i):
            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value
                colname = corr_matrix.columns[i]  # getting the name of column
                col_corr.add(colname)
    return col_corr

train_data = pd.read_csv('train.csv')
valid_data = pd.read_csv('valid.csv')
test_data = pd.read_csv('test.csv')

test_label1=test_data.copy()
id=test_label1["ID"]

X_train = train_data.drop(columns=["label_1", "label_2", "label_3", "label_4"])
y_test_train = train_data["label_1"]

X_valid = valid_data.drop(columns=["label_1", "label_2", "label_3", "label_4"])
Y_valid = valid_data["label_1"]

X_test = valid_data.drop(columns=["label_1", "label_2", "label_3", "label_4"])
Y_test = valid_data["label_1"]

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Calculate the correlation matrix for X_train
corr_matrix = X_train.corr()

# Create a heatmap to visualize the correlation matrix
plt.figure(figsize=(10, 8))  # Set the figure size
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Matrix Heatmap")
plt.show()

#Calculate the correlation in X_train
threshold = 0.9
correlated_cols = correlation(X_train, threshold)
print(correlated_cols)
#Remove correlated columns from X_train, X_valid, and X_test
X_train = X_train.drop(columns=correlated_cols)
X_valid = X_valid.drop(columns=correlated_cols)
X_test = X_test.drop(columns=correlated_cols)

#create separate dataframes for each label
x_train = {}
x_valid = {}
y_train = {}
y_valid = {}
x_test = {}
y_test = {}
Labels = ["label_1", "label_2", "label_3", "label_4"]
Features = np.array(train_data.drop(columns=["label_1", "label_2", "label_3", "label_4"]).columns)

for label in Labels:
  tr_data = train_data[train_data["label_2"].notna()] if label == "label_2" else train_data
  vl_data = valid_data[valid_data["label_2"].notna()] if label == "label_2" else valid_data

  #standardize data
  scaler = StandardScaler()

  x_train[label] = pd.DataFrame(scaler.fit_transform(tr_data.drop(Labels, axis=1)), columns=Features)
  y_train[label] = tr_data[label]
  x_valid[label] = pd.DataFrame(scaler.transform(vl_data.drop(Labels, axis=1)), columns=Features)
  y_valid[label] = vl_data[label]
  x_test[label] = pd.DataFrame(scaler.transform(test_data.drop(["ID"], axis=1)), columns=Features)

"""Removing Correlated features"""

for label in Labels:
    # Calculate the correlation matrix for the x_train[label]
    corr_features = correlation(x_train[label], threshold=0.9)  # Adjust the threshold as needed

    # Remove correlated features from x_train[label]
    x_train[label] = x_train[label].drop(columns=corr_features)
    x_valid[label] = x_valid[label].drop(columns=corr_features)
    x_test[label] = x_test[label].drop(columns=corr_features)

"""<h4>Label 1</h4>"""

###### Initial accuracy with svm_model
svm_model_1 = SVC(kernel="linear")
svm_model_1.fit(x_train["label_1"], y_train["label_1"])
accuracy_label_1 = AccuracyScore(svm_model_1, x_valid["label_1"], y_valid["label_1"])

#Apply PCA -Feature Extraction
pca_label_1 = PCA(n_components=0.99, svd_solver="full")
pca_label_1.fit(x_train["label_1"])
x_train_label_1_PCA = pd.DataFrame(pca_label_1.transform(x_train["label_1"]))
print(x_train_label_1_PCA.shape)
x_valid_label_1_PCA = pd.DataFrame(pca_label_1.transform(x_valid["label_1"]))

svm_model_1.fit(x_train_label_1_PCA, y_train["label_1"])
acc_pca = AccuracyScore(svm_model_1, x_valid_label_1_PCA, y_valid["label_1"])

param_dist = {
    'C': [100, 10, 1],  # Continuous uniform distribution for 'C'
    'kernel': ['rbf', 'linear'],  # Categorical distribution for 'kernel'
    'gamma': [0.001, 0.01, 0.1],  # Continuous uniform distribution for 'gamma'
    'degree': [2, 3, 4, 5],  # Polynomial degree for 'poly' kernel
    'coef0': [0.0, 1.0, 2.0],  # Independent term in the kernel function
}

# Create a RandomizedSearchCV object
random_search_label_1 = RandomizedSearchCV(svm_model_1, param_dist, cv=5, scoring='accuracy',
                              n_iter=5, random_state=42, verbose=3, n_jobs=-1)
random_search_label_1.fit(x_train_label_1_PCA, y_train['label_1'])
print("Best Hyperparameters:", random_search_label_1.best_params_)

# Get the best hyperparameters and the corresponding model
best_model_label_1 = random_search_label_1.best_estimator_

# Evaluate the best model on validation set
acc_best_model_label_1 = best_model_label_1.score(x_valid_label_1_PCA, y_valid["label_1"])

print("Validation Accuracy with Best Model:", acc_best_model_label_1)

#Check accuracy with tuned model on validation set
svm_model_1_tuned = SVC(kernel="rbf", C=100, gamma=0.001,degree=5,coef0=2.0)
svm_model_1_tuned.fit(x_train_label_1_PCA, y_train["label_1"])
accuracy_label_1 = AccuracyScore(svm_model_1_tuned, x_valid_label_1_PCA, y_valid["label_1"])

#Predict on test set with tuned model and PCA
y_pred_label_1 = svm_model_1_tuned.predict(pca_label_1.transform(x_test["label_1"]))

prediction_df=pd.DataFrame({"ID": id, "label_1": y_pred_label_1})
prediction_df

"""<h4>Label 2</h4>"""

svm_model_2 = SVC()
svm_model_2.fit(x_train["label_2"], y_train["label_2"])
acc = AccuracyScore(
    svm_model_2, x_valid["label_2"], y_valid["label_2"])

pca_label_2 = PCA(n_components=0.99, svd_solver="full")
pca_label_2.fit(x_train["label_2"])
x_train_label2_PCA = pd.DataFrame(pca_label_2.transform(x_train["label_2"]))
print(x_train_label2_PCA.shape)
x_valid_label2_PCA = pd.DataFrame(pca_label_2.transform(x_valid["label_2"]))

svm_model_2.fit(x_train_label2_PCA, y_train["label_2"])
acc = AccuracyScore(svm_model_2, x_valid_label2_PCA, y_valid["label_2"])

param_grid = {
    'C': [100, 10, 1, 0.1],  # Continuous uniform distribution for 'C'
    'kernel': ['rbf', 'linear'],  # Categorical distribution for 'kernel'
    'gamma': [0.001, 0.01, 0.1, 1],  # Continuous uniform distribution for 'gamma'
    'degree': [2, 3, 4, 5],  # Polynomial degree for 'poly' kernel
    'coef0': [0.0, 0.5, 1.0, 2.0]  # Independent term in the kernel function
}
random_search_label_2 = RandomizedSearchCV(svm_model_1, param_grid, cv=5, scoring='accuracy',
                              n_iter=5, random_state=42, verbose=3, n_jobs=-1)
random_search_label_2.fit(x_train_label2_PCA, y_train['label_2'])
print("Best Hyperparameters:", random_search_label_2.best_params_)

# Get the best hyperparameters and the corresponding model
best_model_label_1 = random_search_label_2.best_estimator_

svm_model_2_tuned = SVC(kernel='linear', C=0.1, gamma=0.01,coef0=0.5,degree=4)
svm_model_2_tuned.fit(x_train["label_2"], y_train["label_2"])
acc = AccuracyScore(svm_model_2_tuned, x_valid["label_2"], y_valid["label_2"])

##Check accuracy with best model on validation set with PCA
acc_best_model_label_2 = AccuracyScore(best_model_label_1, x_valid_label2_PCA, y_valid["label_2"])

#Predict on test set with tuned model without PCA
y_pred_label_2 = svm_model_2_tuned.predict(x_test["label_2"])
y_pred_label_df_2=pd.DataFrame(y_pred_label_2, columns=['label_2'])

merge_df=pd.concat([prediction_df, y_pred_label_df_2],axis=1)

merge_df

"""<h4>Label 3</h4>"""

svm_model_3 = SVC(kernel="linear")
svm_model_3.fit(x_train["label_3"], y_train["label_3"])
acc = AccuracyScore(
    svm_model_3, x_valid["label_3"], y_valid["label_3"])

#Apply PCA - Feature Extraction
pca_label_3 = PCA(n_components=0.95, svd_solver="full")
pca_label_3.fit(x_train["label_3"])
x_train_label_3_PCA = pd.DataFrame(pca_label_3.transform(x_train["label_3"]))
print(x_train_label_3_PCA.shape)
x_valid_label_3_PCA = pd.DataFrame(pca_label_3.transform(x_valid["label_3"]))

svm_model_3.fit(x_train_label_3_PCA, y_train["label_3"])
acc = AccuracyScore(svm_model_3, x_valid_label_3_PCA, y_valid["label_3"])

param_grid = {
    'C': [100, 10, 1, 0.1],  # Continuous uniform distribution for 'C'
    'kernel': ['rbf', 'linear'],  # Categorical distribution for 'kernel'
    'gamma': [0.001, 0.01, 0.1, 1],  # Continuous uniform distribution for 'gamma'
    'degree': [2, 3, 4, 5],  # Polynomial degree for 'poly' kernel
    'coef0': [0.0, 0.5, 1.0, 2.0]  # Independent term in the kernel function
}

random_search_label_3 = RandomizedSearchCV(svm_model_3, param_grid, cv=5, scoring='accuracy',
                              n_iter=5, random_state=42, verbose=3, n_jobs=-1)
random_search_label_3.fit(x_train_label_3_PCA, y_train['label_3'])
print("Best Hyperparameters:", random_search_label_3.best_params_)

# Get the best hyperparameters and the corresponding model
best_model_label_3 = random_search_label_3.best_estimator_

best_model_label_3 = random_search_label_3.best_estimator_
acc_best_model_label_3 = AccuracyScore(best_model_label_3, x_valid_label_3_PCA, y_valid["label_3"])

##Check accuracy with tuned model on validation set without PCA
svm_model_3_tuned = SVC(kernel='linear', C=0.1, gamma=0.01,degree=4,coef0=0.5)
svm_model_3_tuned.fit(x_train["label_3"], y_train["label_3"])
acc = AccuracyScore(svm_model_3_tuned, x_valid["label_3"], y_valid["label_3"])

#Predict on test set with tuned model without PCA
y_pred_label_3 = svm_model_3_tuned.predict(x_test["label_3"])
y_pred_label_df_3=pd.DataFrame(y_pred_label_3, columns=['label_3'])

merge_df=pd.concat([merge_df, y_pred_label_df_3],axis=1)

merge_df

"""<h4>Label 4</h4>"""

svm_model_4 = SVC()
svm_model_4.fit(x_train["label_4"], y_train["label_4"])
acc = AccuracyScore(svm_model_4, x_valid["label_4"], y_valid["label_4"])

pca_label_4 = PCA(n_components=0.95, svd_solver="full")
pca_label_4.fit(x_train["label_4"])
x_train_label_4_PCA = pd.DataFrame(pca_label_4.transform(x_train["label_4"]))
print(x_train_label_4_PCA.shape)
x_valid_label_4_PCA = pd.DataFrame(pca_label_4.transform(x_valid["label_4"]))

svm_model_4.fit(x_train_label_4_PCA, y_train["label_4"])
acc = AccuracyScore(svm_model_4, x_valid_label_4_PCA, y_valid["label_4"])

param_grid = {
    'C': [100, 10, 1],  # Continuous uniform distribution for 'C'
    'kernel': ['rbf', 'linear'],  # Categorical distribution for 'kernel'
    'gamma': [0.001, 0.01, 0.1],  # Continuous uniform distribution for 'gamma'
    'degree': [2, 3, 4, 5],  # Polynomial degree for 'poly' kernel
    'coef0': [0.0, 1.0, 2.0],  # Independent term in the kernel function
    'class_weight': [None, 'balanced']
}

random_search_label_4 = RandomizedSearchCV(svm_model_4, param_grid, cv=5, scoring='accuracy',
                              n_iter=5, random_state=42, verbose=3, n_jobs=-1)
random_search_label_4.fit(x_train_label_4_PCA, y_train['label_4'])
print("Best Hyperparameters:", random_search_label_4.best_params_)

# Get the best hyperparameters and the corresponding model
best_model_label_4 = random_search_label_4.best_estimator_

acc_best_model_label_4 = AccuracyScore(best_model_label_4, x_valid_label_4_PCA, y_valid["label_4"])

##Check accuracy with tuned model on validation set with PCA
svm_model_4_tuned = SVC(kernel='rbf', C=100, gamma=0.001)
svm_model_4_tuned.fit(x_train_label_4_PCA, y_train["label_4"])
acc = AccuracyScore(svm_model_4_tuned, x_valid_label_4_PCA, y_valid["label_4"])

##Check accuracy with tuned model on validation set with PCA
svm_model_4_tuned = SVC(kernel='rbf', C=10, gamma=0.001,degree=4,coef0=1.0)
svm_model_4_tuned.fit(x_train_label_4_PCA, y_train["label_4"])
acc = AccuracyScore(svm_model_4_tuned, x_valid_label_4_PCA, y_valid["label_4"])

#Predict on test set with tuned model with PCA
y_pred_label_4 = svm_model_4_tuned.predict(pca_label_4.transform(x_test["label_4"]))
y_pred_label_df_4=pd.DataFrame(y_pred_label_4, columns=['label_3'])

merge_df=pd.concat([merge_df, y_pred_label_df_3],axis=1)

merge_df.to_csv("solutions.csv", index=False)